library(devtools)
install_github("rgardiner90/researchr")
install_github("rgardiner90/researchr")
data(mtcars)
missing <- mtcars %>%
mutate(mpg = ifelse(mpg > 20, NA, mpg),)
missing <- mtcars %>%
mutate(mpg = ifelse(mpg > 20, NA, mpg),
cyl = ifelse(cyl == 6, NA, cyl))
missing <- mtcars %>%
mutate(mpg = ifelse(mpg > 20, NA, mpg),
cyl = ifelse(cyl == 6, NA, cyl))
library(tidyverse)
missing <- mtcars %>%
mutate(mpg = ifelse(mpg > 20, NA, mpg),
cyl = ifelse(cyl == 6, NA, cyl))
missing
researchr::check_missing_variables(missing)
library(researchr)
check_missing_variables(missing)
document("researchr")
document("researchr.R")
library(devtools)
document
document()
dir()
dir("researchr/man")
dir("/man")
dir("researcher\man")
help(researchr)
help(check_variable_assumptions)
??check_variable_assumptions
??check_variable_assumptions()
?check_missing_variables
library(devtools)
check("researchr")
check()
check()
check()
check()
document()
check()
??check_assumptions()
library(researchr)
?check_assumptions
check()
check()
# check_assumptions(model2)
#' Conditional mean looks at the correlation between the residuals and the numeric
#' variable.  Currently, it is unable to properly evaluate the influence of a
#' categorical variable.
#'
#' @examples
#' # model <- lm(dist ~ speed , data = cars) # running a model
#' # check_assumptions(model)
#'
#' # model2 <- lm(mpg ~ cyl + wt, data = mtcars)
#' # check_assumptions(model2)
check_assumptions <- function(model_name) {
####
# adds residuals
####
resid <- residuals(model_name)
####
# Most tests
####
normality <- moments::jarque.test(resid) # residual test
constant_variance <- car::ncvTest(model_name) # constant variance
autocorrelation <- car::durbinWatsonTest(model_name) # autocorrelation
# putting most tests together
tests <- c("normality", "constant variance", "auto correlation")
values <- c(signif(as.numeric(normality$p.value), 3),
signif(as.numeric(constant_variance$p), 3), signif(as.numeric(autocorrelation$p), 3))
problems <- ifelse(values < 0.05, "problem", "no problem")
tests <- cbind(tests, values, problems)
####
# adding multicollinearity
####
viffy <- ifelse(length(model_name$coefficients) < 3,
"only one IV", max(car::vif(model_name)))
viffy_results <- ifelse(viffy == "only one IV", "NA",
ifelse(viffy > 10, "problem",
ifelse(viffy > 4, "potential problem", "no problem")))
vif <- c("multicollinearity: vif", viffy, viffy_results)
####
# adding conditional mean of the errors
####
resid <- residuals(model_name)
# running correlation between variables and residual (conditional mean of error is zero)
correlation <- sapply(model_name$model,
function(x) ifelse(is.factor(x),
max(abs(tapply(resid, x, mean))),
cor(resid, x)))
cor_problem <- ifelse(correlation > 0.2,
"potential problem, unkown if factor", "no problem, unknown if factor")
cor_output <-cbind(paste0("conditional mean: ",
variable.names(model_name)), signif(correlation, 3), cor_problem)
correlation_output <- cor_output[-1,]
# creating the object to return
testing <- data.frame(rbind(tests, vif, correlation_output))
rownames(testing) <- c()
# testing$values <- round(as.numeric(testing$values), 3)
return(testing)
}
model <- lm(dist ~ speed , data = cars) # running a model
check_assumptions(model)
check()
#' categorical variable.
#'
#' @export
#'
#' @example
#' model <- lm(dist ~ speed , data = cars) # running a model
#' check_assumptions(model)
#'
#' model2 <- lm(mpg ~ cyl + wt, data = mtcars)
#' check_assumptions(model2)
check_assumptions <- function(model_name) {
####
# adds residuals
####
resid <- residuals(model_name)
####
# Most tests
####
normality <- moments::jarque.test(resid) # residual test
constant_variance <- car::ncvTest(model_name) # constant variance
autocorrelation <- car::durbinWatsonTest(model_name) # autocorrelation
# putting most tests together
tests <- c("normality", "constant variance", "auto correlation")
values <- c(signif(as.numeric(normality$p.value), 3),
signif(as.numeric(constant_variance$p), 3), signif(as.numeric(autocorrelation$p), 3))
problems <- ifelse(values < 0.05, "problem", "no problem")
tests <- cbind(tests, values, problems)
####
# adding multicollinearity
####
viffy <- ifelse(length(model_name$coefficients) < 3,
"only one IV", max(car::vif(model_name)))
viffy_results <- ifelse(viffy == "only one IV", "NA",
ifelse(viffy > 10, "problem",
ifelse(viffy > 4, "potential problem", "no problem")))
vif <- c("multicollinearity: vif", viffy, viffy_results)
####
# adding conditional mean of the errors
####
resid <- residuals(model_name)
# running correlation between variables and residual (conditional mean of error is zero)
correlation <- sapply(model_name$model,
function(x) ifelse(is.factor(x),
max(abs(tapply(resid, x, mean))),
cor(resid, x)))
cor_problem <- ifelse(correlation > 0.2,
"potential problem, unkown if factor", "no problem, unknown if factor")
cor_output <-cbind(paste0("conditional mean: ",
variable.names(model_name)), signif(correlation, 3), cor_problem)
correlation_output <- cor_output[-1,]
# creating the object to return
testing <- data.frame(rbind(tests, vif, correlation_output))
rownames(testing) <- c()
# testing$values <- round(as.numeric(testing$values), 3)
return(testing)
}
check()
check()
check()
check()
check()
check()
check()
check()
check()
check()
library(devtools)
check()
check()
check()
library(devtools)
check()
build("researchr")
model <- lm(mpg ~ ., data = cars)
model
cars
model <- lm(dist ~ ., data = cars)
model
library(researchr)
check_assumptions(model)
?check_assumptions
document()
devtools::document()
library(devtools)
document()
library(devtools)
check()
check()
document()
library(devtools)
document()
document()
library(devtools)
document()
check()
library(devtools)
check()
check()
library(devtools)
document()
library(devtools)
check()
?unnest()
explore_bivariate <- function(data, dependent, independent, p_value = 0.05, type = "graph",
model_type = "ols") {
# getting the names of all the variables
variables <- colnames(data)
# getting the names of the independnet variables
independent_text <- independent
independent_variable <- data[, independent_text]
# setting the dv
dependent_text <- dependent
dependent_variable <- data[, dependent_text]
# setting the iv list
iv_list <- independent_text
# determining whether ols or logit
modelType <- ifelse(tolower(model_type) == "ols", "gaussian",
ifelse(tolower(model_type) == "logit", "binomial",
"please select either 'ols' or 'logit'"))
# running the models
models <- lapply(iv_list, function(x) {
broom::tidy(glm(substitute(dv ~ i, list(dv = as.name(dependent_text),
i = as.name(x))),
data = data,
family = modelType))
})
# getting output
if(type == "graph") {
results <- models %>%
tibble::tibble() %>%
tidyr::unnest(id = "model_number") %>%
dplyr::filter(term != "(Intercept)") %>%
dplyr::select(model_number, term, estimate, std.error) %>%
dplyr::mutate(lower = (estimate - (std.error * 1.96)),
upper = (estimate + (std.error * 1.96)),
term = forcats::fct_reorder(term, estimate),
significance = ifelse(estimate > 0 & lower > 0, "positive",
ifelse(estimate < 0 & upper < 0, "negative", "not significant"))) %>%
ggplot2::ggplot(ggplot2::aes(x = term, y = estimate,
ymin = lower, ymax = upper, color = significance)) +
ggplot2::theme_minimal() +
ggplot2::geom_hline(yintercept = 0.0, color = "red", lty = 2) +
ggplot2::geom_point() +
ggplot2::geom_linerange() +
ggplot2::labs(title = "Results are from bivariate tests, not a single model.",
caption = "Graph results show a 95% confidence interval",
x = "", y = "Coefficient") +
ggplot2::coord_flip() +
ggplot2::scale_color_manual(values = c("red2", "gray", "#7CAE00"))
return(results)
} else if(type == "table") {
results <- models %>%
tibble::tibble() %>%
tidyr::unnest(.id = "model_number") %>%
dplyr::filter(term != "(Intercept)") %>%
dplyr::mutate(significance = ifelse(p.value < p_value, 1, 0))
return(results)
} else {
return("Please select either 'graph' or 'table' for type")
}
}
explore_bivariate(mtcars, "mpg", c("cyl", "disp", "hp", "drat"), p_value = 0.00001)
explore_bivariate <- function(data, dependent, independent, p_value = 0.05, type = "graph",
model_type = "ols") {
# getting the names of all the variables
variables <- colnames(data)
# getting the names of the independnet variables
independent_text <- independent
independent_variable <- data[, independent_text]
# setting the dv
dependent_text <- dependent
dependent_variable <- data[, dependent_text]
# setting the iv list
iv_list <- independent_text
# determining whether ols or logit
modelType <- ifelse(tolower(model_type) == "ols", "gaussian",
ifelse(tolower(model_type) == "logit", "binomial",
"please select either 'ols' or 'logit'"))
# running the models
models <- lapply(iv_list, function(x) {
broom::tidy(glm(substitute(dv ~ i, list(dv = as.name(dependent_text),
i = as.name(x))),
data = data,
family = modelType))
})
# getting output
if(type == "graph") {
results <- models %>%
tibble::tibble() %>%
tidyr::unnest(cols = "model_number") %>%
dplyr::filter(term != "(Intercept)") %>%
dplyr::select(model_number, term, estimate, std.error) %>%
dplyr::mutate(lower = (estimate - (std.error * 1.96)),
upper = (estimate + (std.error * 1.96)),
term = forcats::fct_reorder(term, estimate),
significance = ifelse(estimate > 0 & lower > 0, "positive",
ifelse(estimate < 0 & upper < 0, "negative", "not significant"))) %>%
ggplot2::ggplot(ggplot2::aes(x = term, y = estimate,
ymin = lower, ymax = upper, color = significance)) +
ggplot2::theme_minimal() +
ggplot2::geom_hline(yintercept = 0.0, color = "red", lty = 2) +
ggplot2::geom_point() +
ggplot2::geom_linerange() +
ggplot2::labs(title = "Results are from bivariate tests, not a single model.",
caption = "Graph results show a 95% confidence interval",
x = "", y = "Coefficient") +
ggplot2::coord_flip() +
ggplot2::scale_color_manual(values = c("red2", "gray", "#7CAE00"))
return(results)
} else if(type == "table") {
results <- models %>%
tibble::tibble() %>%
tidyr::unnest(.id = "model_number") %>%
dplyr::filter(term != "(Intercept)") %>%
dplyr::mutate(significance = ifelse(p.value < p_value, 1, 0))
return(results)
} else {
return("Please select either 'graph' or 'table' for type")
}
}
explore_bivariate(mtcars, "mpg", c("cyl", "disp", "hp", "drat"), p_value = 0.00001)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(psych)
library(sem)
library(broom)
all_schools <- read_excel("R:/Level 2/17-18_All Schools.xlsx") %>%
filter(BarResult!="Did not take")
all_schools$Race2 <- ifelse(all_schools$Race=="Black or African American" |
all_schools$Race=="Black or African american",
paste("Black"),
all_schools$Race)
all_schools$Race2 <- ifelse(all_schools$Race=="Hispanics of any race",
paste("Hispanic"), all_schools$Race2)
all_schools$Race2 <- ifelse(all_schools$Race=="White",
paste("White"), all_schools$Race2)
all_schools$Race2 <- ifelse(all_schools$Race=="Asian",
paste("Asian"), all_schools$Race2)
all_schools$Race2 <- ifelse(all_schools$Race=="American Indian or Alaska Native" |
all_schools$Race=="Native Hawaiian or Other Pacific Islander",
paste("Other"), all_schools$Race2)
all_schools$Race2 <- ifelse(all_schools$Race=="Nonresident alien"|
all_schools$Race=="Two or More Races" |
all_schools$Race=="Race and Ethnicity Unknown",
paste("Other"), all_schools$Race2)
all_schools$Race2 <- factor(all_schools$Race2)
all_schools$Race2 <- factor(all_schools$Race2, levels=c("White", "Hispanic", "Asian", "Black", "Other"))
table(all_schools$Race2)
all_schools$SchoolID <- as.factor(all_schools$SchoolID)
all_schools$Gender <- as.factor(all_schools$Gender)
bar_prep <- all_schools %>%
group_by(SchoolID) %>%
mutate(scaled_yr1 = round(scale(Yr1_GPA), 2)) %>%
ungroup() %>%
select(BarResult, UGPA, LSAT, scaled_yr1, Race2, Gender,
SchoolID, CreditHrs_Doctrinal, firstgen,
LTTLL, envschol, exams, gnleged, memorize) %>%
na.omit() %>%
mutate(BarResult = ifelse(BarResult=="Pass", 1, 0)) %>%
select(SchoolID, everything()) %>%
mutate(firstgen = firstgen -1,
envschol = ifelse(envschol <=2, 0,
ifelse(envschol == 3, 1, 2)), # very little or some = 0, quite a bit = 1, very much = 2
exams = ifelse(exams <= 3, 0,
ifelse(exams == 4, 1, 2)), # very little to 3 (not specified) = 0, 4 (middle) = 1, 5 to very much = 2
gnleged = ifelse(gnleged <=2, 0,
ifelse(gnleged==3, 1, 2)), # very little or some = 0, quiet a bit = 1, very much = 2
memorize = ifelse(memorize <=2, 0,
ifelse(memorize == 3, 1, 2))) # very little or some = 0, quiet a bit = 1, very much = 2
Prep_model <- glm(BarResult ~ .,data=bar_prep, family="binomial")
summary(Prep_model)
Prep_model2 <- glm(BarResult ~ LTTLL + envschol + exams + gnleged + memorize, data=bar_prep, family = "binomial")
summary(Prep_model2)
car::vif(Prep_model2)
variables <- colnames(bar_prep) %>%
as_tibble() %>%
filter(value != "SchoolID")
iv_list <- names(bar_prep) [3:14]
BarResult <- bar_prep$BarResult
SchoolID <- bar_prep$SchoolID
model <- lapply(iv_list, function(x) {
tidy(glm(substitute(BarResult ~ bar_prep$i + SchoolID, list(i = as.name(x))), family = "binomial"))
})
model_glance <- lapply(iv_list, function(x) {
glance(glm(substitute(BarResult ~bar_prep$i + SchoolID, list(i = as.name(x))), family = "binomial"))
})
model %>%
tibble()
model %>%
tibble() %>%
unnest(.id = "model_number")
model %>%
tibble::tibble() %>%
dplyr::mutate(id = names(.)) %>%
tidyr::unnest(.)
model %>%
tibble::tibble() %>%
dplyr::mutate(id = names(.)) %>%
tidyr::unnest(cols = c(,))
model %>%
tibble::tibble() %>%
dplyr::mutate(id = names(.)) %>%
tidyr::unnest(cols = c(.))
model %>%
tibble::tibble() %>%
dplyr::mutate(id = names(x)) %>%
tidyr::unnest(cols = c(.))
model %>%
tibble::tibble() %>%
tidyr::unnest(cols = c(.))
check()
check()
devtools::use_vignette("my-vignette")
use_vignette("researchr-vignette")
library(devtools)
document()
